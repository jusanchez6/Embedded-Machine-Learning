{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SFBFiQlYlva"
      },
      "source": [
        "# Embedded ML - Lab 1.2: Model Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svldvvGfmN8q"
      },
      "source": [
        "In this lab you are asked to create a compressed verion of an ANNs model. You are not allowed to use ML libraries such as SciKit-learn, PyTorch or TensorFlow, but you are allowed to use standard libraries such as math, numpy and matplotlib if needed. You are given some code but you are expected to write some more and be able to explain and modify everything. This lab is essential for you to grasp the details of some of the most important techniques for compressing or making ML models more efficient: quantization and pruning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# To run this notebook, locally as a jupyter notebook, you need to install the following packages:\n",
        "\n",
        "#1. Create a virtual environment through conda or venv\n",
        "#   For example, using conda:\n",
        "#                conda create -n [myenv] python=3.8\n",
        "#                conda activate [myenv]\n",
        "#   Or using venv:\n",
        "#                python3 -m venv [myenv]\n",
        "#                source [myenv]/bin/activate\n",
        "#\n",
        "#\n",
        "#2. Activate the virtual environment\n",
        "#3. Install the required packages using pip\n",
        "#4. Run the notebook\n",
        "\n",
        "\n",
        "# Install the required packages\n",
        "%pip install numpy -q\n",
        "%pip install matplotlib -q\n",
        "%pip install pandas -q\n",
        "\n",
        "# It use tensorflow JUST to load the minist dataset\n",
        "%pip install tensorflow -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQK0RRRuY3rJ"
      },
      "source": [
        "### Learning outcomes\n",
        "\n",
        "\n",
        "* Explain the basic concepts of compression in ANNs\n",
        "* Apply range tuning and centering when doing quantization\n",
        "* Calculate and analyze the impact of quantization and pruning on memory and computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wat6Kxul5R"
      },
      "source": [
        "### Naive quantization\n",
        "Quantization means reducing the precission of model parameters and mainly targets weights, since they represent the most volumne of memory and processing in ANNs.\n",
        "\n",
        "Take the code from the last part of Lab 1.1 (MNIST model) and add methods to export and import weights to and from a binary file, making sure both processes work with your code in such a way that you don't have to train every time you want to run inference, but insted, the wieghts are loaded into the model when needed. Investigate which serialization/desarialization options exist in Python and choose one that you understand.\n",
        "\n",
        "Then, create two additional inference methods: FP16 and INT8. The FP16 method should treat all computations in the network involving the weights, as 16-bit floating-point. The INT8 method should work with 8-bit integers instead. In both cases, use the native datatype conversion methods. Investigate the NumPy methods available to enforce the desired datatypes.\n",
        "\n",
        "Run the two quantized models and compare them with the baseline in terms of model size, accuracy and latency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss = 0.2904\n",
            "Epoch 100: Loss = 0.0580\n",
            "Epoch 200: Loss = 0.0428\n",
            "Epoch 300: Loss = 0.0345\n",
            "Epoch 400: Loss = 0.0290\n",
            "Epoch 500: Loss = 0.0249\n",
            "Epoch 600: Loss = 0.0218\n",
            "Epoch 700: Loss = 0.0193\n",
            "Epoch 800: Loss = 0.0173\n",
            "Epoch 900: Loss = 0.0156\n",
            "Epoch 1000: Loss = 0.0141\n",
            "Epoch 1100: Loss = 0.0129\n",
            "Epoch 1200: Loss = 0.0118\n",
            "Epoch 1300: Loss = 0.0109\n",
            "Epoch 1400: Loss = 0.0101\n",
            "Epoch 1500: Loss = 0.0095\n",
            "Epoch 1600: Loss = 0.0089\n",
            "Epoch 1700: Loss = 0.0083\n",
            "Epoch 1800: Loss = 0.0079\n",
            "Epoch 1900: Loss = 0.0074\n",
            "Pesos guardados en 'weights_fp32.npz'\n"
          ]
        }
      ],
      "source": [
        "# Here comes the mnist model code\n",
        "\n",
        "# Load the dataset\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalization\n",
        "x_train = x_train.reshape((-1, 28 * 28))/ 255\n",
        "x_test = x_test.reshape((-1, 28 * 28)) / 255\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# select a subset of the dataset\n",
        "x_subset = x_train[:1000]\n",
        "y_subset = y_train[:1000]\n",
        "\n",
        "\n",
        "\n",
        "# define the neural network model\n",
        "class NeuralNetwork_np:\n",
        "    \"\"\"\n",
        "    A simple feedforward neural network with one hidden layer using NumPy's dot product.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) * np.sqrt(1 / self.input_size)\n",
        "        self.bias_input_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.bias_hidden_output = np.zeros((1, self.output_size))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "\n",
        "        x = np.clip(x, -500, 500)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        self.hidden_input = np.dot(self.input, self.weights_input_hidden) + self.bias_input_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "\n",
        "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_hidden_output\n",
        "        self.output = self.sigmoid(self.output_input)\n",
        "\n",
        "        return self.output\n",
        "    \n",
        "    def forward_fp16(self, x):\n",
        "        x = x.astype(np.float16)\n",
        "        self.input = x\n",
        "        self.hidden_input = np.dot(self.input, self.weights_input_hidden.astype(np.float16)) + self.bias_input_hidden.astype(np.float16)\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "\n",
        "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output.astype(np.float16)) + self.bias_hidden_output.astype(np.float16)\n",
        "        self.output = self.sigmoid(self.output_input)\n",
        "\n",
        "        return self.output\n",
        "    \n",
        "    def forward_int8(self, x):\n",
        "        x = x.astype(np.int8)\n",
        "        self.input = x\n",
        "        self.hidden_input = np.dot(self.input, self.weights_input_hidden.astype(np.int8)) + self.bias_input_hidden.astype(np.int8)\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "\n",
        "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output.astype(np.int8)) + self.bias_hidden_output.astype(np.int8)\n",
        "        self.output = self.sigmoid(self.output_input)\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, x, y, output, learning_rate):\n",
        "        error = y - output\n",
        "        d_output = error * self.sigmoid_derivative(output)\n",
        "\n",
        "        hidden_error = np.dot(d_output, self.weights_hidden_output.T)\n",
        "        d_hidden = hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        self.weights_hidden_output += np.dot(self.hidden_output.T, d_output) * learning_rate\n",
        "        self.bias_hidden_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "        self.weights_input_hidden += np.dot(x.T, d_hidden) * learning_rate\n",
        "        self.bias_input_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, x, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(x)\n",
        "            self.backward(x, y, output, learning_rate)\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean(np.square(y - output))\n",
        "                print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "    def cast_weights(self, dtype=np.float32):\n",
        "        self.weights_input_hidden = self.weights_input_hidden.astype(dtype)\n",
        "        self.bias_input_hidden = self.bias_input_hidden.astype(dtype)\n",
        "        self.weights_hidden_output = self.weights_hidden_output.astype(dtype)\n",
        "        self.bias_hidden_output = self.bias_hidden_output.astype(dtype)\n",
        "\n",
        "        print(f\"Pesos convertidos a {dtype}\")\n",
        "\n",
        "    def save_weights(self, filename):\n",
        "        np.savez(filename,\n",
        "                weights_input_hidden=self.weights_input_hidden,\n",
        "                bias_input_hidden=self.bias_input_hidden,\n",
        "                weights_hidden_output=self.weights_hidden_output,\n",
        "                bias_hidden_output=self.bias_hidden_output)\n",
        "        print(f\"Pesos guardados en '{filename}'\")\n",
        "\n",
        "    def load_weights(self, filename):\n",
        "        data = np.load(filename)\n",
        "        self.weights_input_hidden = data['weights_input_hidden']\n",
        "        self.bias_input_hidden = data['bias_input_hidden']\n",
        "        self.weights_hidden_output = data['weights_hidden_output']\n",
        "        self.bias_hidden_output = data['bias_hidden_output']\n",
        "        print(f\"Pesos cargados desde '{filename}'\")\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "def evaluate(model, x, y_true):\n",
        "    y_pred = model.forward(x)\n",
        "    predictions = np.argmax(y_pred, axis=1)\n",
        "    labels = np.argmax(y_true, axis=1)\n",
        "    accuracy = np.mean(predictions == labels)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Training of the model and saving the weights\n",
        "\n",
        "model = NeuralNetwork_np(input_size= 28 * 28, hidden_size= 10, output_size=10)\n",
        "model.train(x_subset, y_subset, epochs=2000, learning_rate=0.001)\n",
        "\n",
        "model.save_weights(filename=\"weights_fp32.npz\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pesos cargados desde 'weights_fp32.npz'\n",
            "Pesos convertidos a <class 'numpy.float16'>\n",
            "Pesos guardados en 'weights_fp16.npz'\n",
            "Pesos convertidos a <class 'numpy.int8'>\n",
            "Pesos guardados en 'weights_int8.npz'\n",
            "\n",
            " Model performance comparison\n",
            "\n",
            "Model  forward time (ms)  Accuracy (%)  Size (MB)\n",
            " FP32           1.445770          86.0   0.061781\n",
            " FP16           1.134634          86.0   0.016233\n",
            " INT8           1.095772           2.0   0.008642\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "results = {\n",
        "    \"Model\": [],\n",
        "    \"forward time (ms)\": [],\n",
        "    \"Accuracy (%)\": [],\n",
        "    \"Size (MB)\": []\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# just another instance of the model\n",
        "\n",
        "nn = NeuralNetwork_np(input_size= 28 * 28, hidden_size= 10, output_size=10)\n",
        "\n",
        "nn.load_weights(\"weights_fp32.npz\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "start_time = time.time()\n",
        "accuracy = evaluate(nn, x_test[:100], y_test[:100])\n",
        "end_time = time.time()\n",
        "forward_time = (end_time - start_time) * 1000  # Convertir a milisegundos\n",
        "\n",
        "\n",
        "results[\"Model\"].append(\"FP32\")\n",
        "results[\"forward time (ms)\"].append(forward_time)\n",
        "results[\"Accuracy (%)\"].append(accuracy*100)\n",
        "results[\"Size (MB)\"].append(os.path.getsize(\"weights_fp32.npz\") / (1024 * 1024))  # Convertir a MB\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "nn.cast_weights(dtype=np.float16)\n",
        "\n",
        "start_time = time.time()\n",
        "accuracy = evaluate(nn, x_test[:100], y_test[:100])\n",
        "end_time = time.time()\n",
        "forward_time = (end_time - start_time) * 1000  # Convertir a milisegundos\n",
        "\n",
        "nn.save_weights(\"weights_fp16.npz\")\n",
        "\n",
        "results[\"Model\"].append(\"FP16\")\n",
        "results[\"forward time (ms)\"].append(forward_time)\n",
        "results[\"Accuracy (%)\"].append(accuracy*100)\n",
        "results[\"Size (MB)\"].append(os.path.getsize(\"weights_fp16.npz\") / (1024 * 1024))  # Convertir a MB\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "nn.cast_weights(dtype=np.int8)\n",
        "\n",
        "start_time = time.time()\n",
        "accuracy = evaluate(nn, x_test[:100], y_test[:100])\n",
        "end_time = time.time()\n",
        "forward_time = (end_time - start_time) * 1000  # Convertir a milisegundos\n",
        "\n",
        "nn.save_weights(\"weights_int8.npz\")\n",
        "\n",
        "results[\"Model\"].append(\"INT8\")\n",
        "results[\"forward time (ms)\"].append(forward_time)\n",
        "results[\"Accuracy (%)\"].append(accuracy*100)\n",
        "results[\"Size (MB)\"].append(os.path.getsize(\"weights_int8.npz\") / (1024 * 1024))  # Convertir a MB\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convertir a DataFrame de pandas\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n Model performance comparison\\n\")\n",
        "print(df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQD3Y7a_wFa"
      },
      "source": [
        "### Range tuning and centering\n",
        "For quantization to be effective, you should smartly choose the range of numbers you will code with the fewer bits available after quantization. To do so, you should evaluate the dynamic ranges of the variables to be quantized and map the values using that as the full range.\n",
        "\n",
        "Make a histogram plot of the model weights in order to verify their range. Then write a function to quantize the weights stored in the exported binary file to INT8 and store the resulting weights in another file. Finally, run again the INT8 quantized inference with the newly computed weights and compare with the previous versions using the same metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "eDMywPk5qZiV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pesos convertidos a <class 'numpy.float32'>\n",
            "Pesos cargados desde 'weights_fp32.npz'\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pesos cargados desde 'quantized_weights.npz'\n",
            "Accuracy with quantized weights: 86.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_histogram(weights):\n",
        "    \"\"\"Plot histogram of all model weights.\"\"\"\n",
        "    all_weights = np.concatenate([w.flatten() for w in weights])\n",
        "    plt.hist(all_weights, bins=100, alpha=0.7, color='skyblue')\n",
        "    plt.title(\"Histogram of model weights\")\n",
        "    plt.xlabel(\"Weight value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.xlim(-1, 1)\n",
        "    \n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def quantize_INT8(weights):\n",
        "    \"\"\"Quantize weights to INT8 using symmetric quantization.\"\"\"\n",
        "    weights_int8 = []\n",
        "    scales = []\n",
        "    for w in weights:\n",
        "        max_val = np.max(np.abs(w))\n",
        "        scale = max_val / 127.0 if max_val != 0 else 1.0\n",
        "        w_int8 = np.clip(np.round(w / scale), -128, 127).astype(np.int8)\n",
        "        weights_int8.append(w_int8)\n",
        "        scales.append(scale)\n",
        "    return weights_int8, scales\n",
        "\n",
        "def save_quantized_weights(weights_int8, scales_int8, filename):\n",
        "    \"\"\"Save quantized weights and scales to a .npz file.\"\"\"\n",
        "    # Crear un diccionario con los pesos cuantizados y las escalas\n",
        "    np.savez(filename, \n",
        "             weights_input_hidden=weights_int8[0],\n",
        "             bias_input_hidden=weights_int8[1],\n",
        "             weights_hidden_output=weights_int8[2],\n",
        "             bias_hidden_output=weights_int8[3],\n",
        "             scale_input_hidden=scales_int8[0],\n",
        "             scale_bias_input_hidden=scales_int8[1],\n",
        "             scale_hidden_output=scales_int8[2],\n",
        "             scale_bias_hidden_output=scales_int8[3])\n",
        "\n",
        "\n",
        "nn.cast_weights(dtype=np.float32)\n",
        "weights_fp32 = [\n",
        "    model.weights_input_hidden,\n",
        "    model.bias_input_hidden,\n",
        "    model.weights_hidden_output,\n",
        "    model.bias_hidden_output\n",
        "]\n",
        "\n",
        "\n",
        "nn.load_weights(\"weights_fp32.npz\")\n",
        "weights_fp32 = [\n",
        "    model.weights_input_hidden.astype(np.float16),\n",
        "    model.bias_input_hidden.astype(np.float16),\n",
        "    model.weights_hidden_output.astype(np.float16),\n",
        "    model.bias_hidden_output.astype(np.float16)\n",
        "]\n",
        "\n",
        "plot_histogram(weights_fp32)\n",
        "\n",
        "weights_int8, scales_int8 = quantize_INT8(weights_fp32)\n",
        "\n",
        "save_quantized_weights(weights_int8, scales_int8, 'quantized_weights.npz')\n",
        "\n",
        "\n",
        "# Load quantized weights\n",
        "nn.load_weights(\"quantized_weights.npz\")\n",
        "\n",
        "# test quantized weights\n",
        "accuracy = evaluate(model, x_test[:100], y_test[:100])\n",
        "print(f\"Accuracy with quantized weights: {accuracy*100:.2f}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDh7MZVJEuhd"
      },
      "source": [
        "### Pruning\n",
        "Besides reducing precision for the network weights, we can also decide to eliminate network connections that do not contribute significantly to the model. This can be achieved by simply removing the connections whose weights are closest to zero.\n",
        "\n",
        "In this part of the lab you are asked to generate three pruned versions of the original model by setting to zero some of the weights:\n",
        "\n",
        "\n",
        "*   Set to zero the smallest 10% of weights\n",
        "*   Set to zero the smallest 30% of weights\n",
        "*   Set to zero the smallest 50% of weights\n",
        "\n",
        "Report the accuracy for each model against the estimated memory savings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "aP3szogQIn3I"
      },
      "outputs": [],
      "source": [
        "def prune_model(weights, percentage):\n",
        "  # set to zero the smallest weights, according to the given percentage\n",
        "\n",
        "  weights_pruned = []\n",
        "\n",
        "  for w in weights:\n",
        "        # Aplanar y obtener el umbral\n",
        "        flat_w = np.abs(w.flatten())\n",
        "        k = int(len(flat_w) * percentage / 100.0)\n",
        "        if k == 0:\n",
        "            weights_pruned.append(w.copy())\n",
        "            continue\n",
        "        \n",
        "        threshold = np.partition(flat_w, k)[k]\n",
        "\n",
        "        # Crear una máscara para poner en cero los menores a ese umbral\n",
        "        pruned_w = np.where(np.abs(w) <= threshold, 0, w)\n",
        "        weights_pruned.append(pruned_w)\n",
        "        \n",
        "  return weights_pruned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pesos cargados desde 'pruned_weights_10.npz'\n",
            "Accuracy with pruned weights (10%): 85.00%\n",
            "Pesos cargados desde 'pruned_weights_30.npz'\n",
            "Accuracy with pruned weights (30%): 85.00%\n",
            "Pesos cargados desde 'pruned_weights_50.npz'\n",
            "Accuracy with pruned weights (50%): 77.00%\n"
          ]
        }
      ],
      "source": [
        "# Supongamos que weights_fp32 es una lista con tus pesos originales\n",
        "weights_pruned_10 = prune_model(weights_fp32, 10)\n",
        "weights_pruned_30 = prune_model(weights_fp32, 30)\n",
        "weights_pruned_50 = prune_model(weights_fp32, 50)\n",
        "\n",
        "# save the pruned weights\n",
        "save_quantized_weights(weights_pruned_10, scales_int8, 'pruned_weights_10.npz')\n",
        "save_quantized_weights(weights_pruned_30, scales_int8, 'pruned_weights_30.npz')\n",
        "save_quantized_weights(weights_pruned_50, scales_int8, 'pruned_weights_50.npz')\n",
        "\n",
        "\n",
        "# Load pruned weights\n",
        "nn.load_weights(\"pruned_weights_10.npz\")\n",
        "# test pruned weights\n",
        "accuracy = evaluate(nn, x_test[:100], y_test[:100])\n",
        "print(f\"Accuracy with pruned weights (10%): {accuracy*100:.2f}%\")\n",
        "\n",
        "nn.load_weights(\"pruned_weights_30.npz\")\n",
        "# test pruned weights\n",
        "accuracy = evaluate(nn, x_test[:100], y_test[:100])\n",
        "print(f\"Accuracy with pruned weights (30%): {accuracy*100:.2f}%\")\n",
        "\n",
        "nn.load_weights(\"pruned_weights_50.npz\")\n",
        "# test pruned weights\n",
        "accuracy = evaluate(nn, x_test[:100], y_test[:100])\n",
        "print(f\"Accuracy with pruned weights (50%): {accuracy*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuLQlI19ItIZ"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "Discuss the following questions based on the lab experiments and the theory studied:\n",
        "\n",
        "\n",
        "*   What are the advantages an disadvantages of storing model weights in different formats?\n",
        "*   How much reduction in model memory requirements can be achieved by each of the versions obtained?\n",
        "*   What are the posible computational advantages of the obtained models and how do they depend on the hardware?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solution\n",
        "\n",
        "## INT8 (8-bit integer):\n",
        "The major advantage with this format is the saving of space, it reduces almost 4 times the size of the model respecting the float32 model, allowing the acceleration of the inference in compatible hardware as MCU's, also consume less energy, ideal to the use in microcontrollers. \n",
        "\n",
        "the disadvantages could be the degradation of the model without the needed calibration or an error in the quantization. \n",
        "\n",
        "## FLOAT16:\n",
        "It reduces the size of the model at the half respecting the float32 model, as seem in this lab it preserved the accuracy better than the int8 model, useful for more sensitive models. In contrast it could cause problems of underflow or overlow if the values aren't property scaled \n",
        "\n",
        "## FLOAT32:\n",
        "Major precision and compatibility with standar libraries, but also major size of the model and use ineficient of the memory and the recurses, it means that cannot be use with hardware limitations \n",
        "\n",
        "\n",
        "## Reduction:\n",
        "\n",
        "* Reducing from float32 to float16 it can be achieved almost a 50% reduction of memory usage, from float32 to int8 it could be almost a 75% of reduction of memory usage. \n",
        "\n",
        "* Prunning the model at 10%, 30% and 50% the memory saving will depend of the compressed representationm usong a eficient compresion it cpuld be achievedd at 10% less memory usage with the 10% prunning, 30% less memory usage with the 30% prunning and 50% less memory usage with the 50% prunning\n",
        "\n",
        "## Obtained models and hardware dependecy:\n",
        "\n",
        "### **Quantized models (INT8)**\n",
        "Whit this model it could ge more inference velocity using specific hardware with int8 operations support like NPUs, it also consem less energy, this allows its use in mobile dispositives and embedded systems\n",
        "\n",
        "### **Prunning models**:\n",
        "By desconectig some neurons it reduces the number of operations, ignoring the cero multiplications, with specialized libraries it also allows to save time of inference. \n",
        "\n",
        "### **Hardware dependecy:**\n",
        "\n",
        "It would be important the kind of model depending of the hardware available for each application, for instance, for CPUs without entire optimized hardware some optimizations of the model could be innefective and could broke the model, but for microncontroles, as the ARM Cortex-M, it is highly recommend to use the INT8 models, because its limitations in resources.   "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
